{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas nescessárias \n",
    "import pandas as pd \n",
    "import json\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from test_functions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lendo dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = open('../config/data_config.json')\n",
    "config_data = json.loads(config_file.read())\n",
    "config_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = open('../config/test_config.json')\n",
    "config_test = json.loads(test_file.read())\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conectando**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect_data = config_data['connection']\n",
    "textEngine = f\"{connect_data['driver']}://{connect_data['user']}:{connect_data['password']}@{connect_data['host']}:{connect_data['port']}/{connect_data['database']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Buscando dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_table(config_data['tables'][0],textEngine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fazendo verificações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_percent_cat(df):\n",
    "    count = 0\n",
    "    for type_table in df.dtypes:\n",
    "        if type_table == \"object\" or str(type_table) == \"category\":\n",
    "            count += 1\n",
    "    print(count)\n",
    "    return count/len(df.columns) \n",
    "\n",
    "out_df['columns'] = df.columns\n",
    "out_df['types'] = dict(df.dtypes)\n",
    "out_df['null_percent'] = dict(df.isnull().sum()/len(df))\n",
    "out_df['n_unique'] = dict(df.nunique())\n",
    "out_df['category_percent'] = dict(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': Index(['index', 'ProductID', 'Date', 'Zip', 'Units', 'Revenue'], dtype='object'),\n",
       " 'types': {'index': dtype('int64'),\n",
       "  'ProductID': dtype('int64'),\n",
       "  'Date': dtype('O'),\n",
       "  'Zip': dtype('int64'),\n",
       "  'Units': dtype('int64'),\n",
       "  'Revenue': dtype('O')},\n",
       " 'null_percent': {'index': 0.0,\n",
       "  'ProductID': 0.0,\n",
       "  'Date': 0.0,\n",
       "  'Zip': 0.0,\n",
       "  'Units': 0.0,\n",
       "  'Revenue': 3.252027361447771e-05},\n",
       " 'n_unique': {'index': 1260752,\n",
       "  'ProductID': 1893,\n",
       "  'Date': 5149,\n",
       "  'Zip': 32595,\n",
       "  'Units': 36,\n",
       "  'Revenue': 3774},\n",
       " 'category_percent': {'index': 1260752,\n",
       "  'ProductID': 1893,\n",
       "  'Date': 5149,\n",
       "  'Zip': 32595,\n",
       "  'Units': 36,\n",
       "  'Revenue': 3774}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Todos as funções**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_functions = [test_columns,test_types,test_null_percent,test_n_uniques,test_category_percent]\n",
    "out_data = {}\n",
    "for function in list_functions:\n",
    "    name_test = function.__name__\n",
    "    retorno = function(df,config_test['salesfacts'])\n",
    "    out_data[name_test] = retorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'salesfacts': {'tests': [],\n",
       "  'cat_types': ['object', 'category'],\n",
       "  'types': {'index': 'int',\n",
       "   'ProductID': 'int',\n",
       "   'Date': 'datetime',\n",
       "   'Zip': 'int',\n",
       "   'Units': 'int',\n",
       "   'Revenue': 'float'},\n",
       "  'max_null': 0.2},\n",
       " 'products': {'tests': [],\n",
       "  'cat_types': ['object', 'category'],\n",
       "  'max_null': 0.2},\n",
       " 'geo': {'tests': [], 'cat_types': ['object', 'category'], 'max_null': 0.2},\n",
       " 'date': {'tests': [], 'cat_types': ['object', 'category'], 'max_null': 0.2},\n",
       " 'manufacturer': {'tests': [],\n",
       "  'cat_types': ['object', 'category'],\n",
       "  'max_null': 0.2}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela salesfacts:\n",
      "Tabela products:\n",
      "Tabela geo:\n",
      "Tabela date:\n",
      "Tabela manufacturer:\n",
      "convert_json\n"
     ]
    }
   ],
   "source": [
    "#Importando bibliotecas nescessárias \n",
    "import pandas as pd \n",
    "import json\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from test_functions import *\n",
    "\n",
    "def conver_json(data):\n",
    "    if type(data) != dict and type(data) != list:\n",
    "        return str(data)\n",
    "    else:\n",
    "        if type(data) == dict:\n",
    "            for key in data:\n",
    "                data[key] = conver_json(data[key])\n",
    "        elif type(data) == list:\n",
    "            for cont in range(len(data)):\n",
    "                data[cont] = conver_json(data[cont])\n",
    "    return data\n",
    "                \n",
    "\n",
    "#Lendo configurações dos dados\n",
    "config_file = open('../config/data_config.json')\n",
    "config_data = json.loads(config_file.read())\n",
    "config_file.close()\n",
    "\n",
    "#Lendo configurações de test\n",
    "test_file = open('../config/test_config.json')\n",
    "config_test = json.loads(test_file.read())\n",
    "test_file.close()\n",
    "\n",
    "#Criando string de conexão\n",
    "connect_data = config_data['connection']\n",
    "textEngine = f\"{connect_data['driver']}://{connect_data['user']}:{connect_data['password']}@{connect_data['host']}:{connect_data['port']}/{connect_data['database']}\"\n",
    "        \n",
    "#lendo tabelas\n",
    "out_data = {} #dicionario de testes das tabelas\n",
    "for table_name in config_data['tables']:\n",
    "    print(f\"Tabela {table_name}:\")\n",
    "    df = pd.read_sql_table(table_name,textEngine)    \n",
    "    list_functions = [test_columns,test_types,test_null_percent,test_n_uniques,test_category_percent]\n",
    "    test_table = {} \n",
    "    for function in list_functions:\n",
    "        name_test = function.__name__\n",
    "        retorno = function(df,config_test[table_name])\n",
    "        test_table[name_test] = retorno\n",
    "    out_data[table_name] = test_table\n",
    "\n",
    "\n",
    "try:\n",
    "    with open('../test_out.json', 'w') as outfile:\n",
    "        json.dump(out_data, outfile, indent=2)\n",
    "        print(\"normal\")\n",
    "except TypeError as error:\n",
    "    with open('../test_out.json', 'w') as outfile:\n",
    "        json.dump(conver_json(out_data), outfile, indent=2)\n",
    "        print('convert_json')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = open('test_out.json').read()\n",
    "out_json = json.loads(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['salesfacts', 'products', 'geo', 'date', 'manufacturer'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_json.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
